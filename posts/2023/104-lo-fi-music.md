---
    date: "31-7-24"
    title: "Lo-Fi music style transfer"
    builder: "Thanakit Chongwilaikasem/มัธยมศึกษาปีที่ 4.0"
    builder_info: " สงขลา -- delta-ducks (จากใบสมัคร)"
    thumbnail: "/images/2023/104/01.jpg"
    links:
        github: "https://github.com/WinWut/Music-style-transfer-to-lofi"
        facebook: "https://www.facebook.com/aibuildersx/posts/pfbid0ou4aqxxWWnQamLFPnvoky4HjEeZQeLsghts3Xqwz7a6B4wbMKExL3bVuKcTXUfiNl"
        blog: "https://medium.com/@thanakit.chongwilaikasem/music-style-transfer-to-lo-fi-4abafb2ace82"
---

![image](/images/2023/104/01.jpg)

- โมเดลแปลงเพลงทุกประเภทให้เป็นแนวเพลง Lo-Fi โดยจะเก็บข้อมูลtarget จากการอัดเสียงในไลฟ์บน Youtube นำไปเข้าโมเดล MelGAN-VC แล้ว Evaluate ด้วยการทำแบบฟอร์มตอบคำถาม และสุดท้าย deploy ลงใน huggingface space โดยใช้ streamlit
- Lo-Fi ซึ่งย่อมาจากคำว่า Low-Fidelity สามารถแปลตรงตัวได้เป็นความหมายว่า ” ความเที่ยงตรงต่ำ ” เป็นเพลงที่จะมีบรรยากาศของเพลงในยุค 80s 90s ที่ถูกอัดโดยเครื่องมือที่มีคุณภาพไม่ค่อยเจ๋งนัก จึงทำให้เพลงมีความถี่ต่ำ และมีมิติน้อย มีเสียงรบกวนเต็มไปหมด ซึ่งเต็มไปด้วยความไม่เพอร์เฟ็กต์เต็มหมด ในวันที่เราไปไกลกับเพลงคุณภาพเยี่ยมอย่าง Hi-Fi จนมันตันแล้ว ทุกอย่างเพอร์เฟ็กต์ไปหมดแล้วสำหรับตอนนี้ เราเลยหันกลับมาหาอะไรที่มันไม่เพอร์เฟ็กต์ดูบ้าง เพราะความไม่เพอร์เฟ็กต์มีเสน่ห์ในตัวมันเองอย่างปฏิเสธไม่ได้
- เป้าหมายของโมเดลคือการลดแรงงานคนในการเปลี่ยนเพลงเป็น Lo-Fi
- สร้างชุดข้อมูลด้วยการอัดเสียง desktop โดยใช้โปรแกรม audacity ในไลฟ์ของช่อง Lo-Fi girl บน youtube
- source audio ใช้ GTZAN Dataset ซึ่งได้ใช้เพลงทั้งหมด 10 ประเภท 1. blues 2. classical 3. country 4. disco 5. hiphop 6. jazz 7. metal 8. rock 9. pop 10. reggae โดยใช้ประเภทละ50เพลง คิดเป็น 500 ไฟล์
- target audio ได้อัดไปทั้งสิ้นเป็นเวลา 7 ชั่วโมง ได้ตัดช่วงเวลาที่ไม่มีเสียงออกไป และทำการแบ่งระยะเวลาช่วงละ30วินาที โดยได้เสียงมาทั้งหมด 800 ไฟล์ ไฟล์ละ 30วินาที รวมทั้งสิ้น 6 ชั่วโมง 40 นาที
- ใช้สถาปัตยกรรม MelGAN-VC ในการเปลี่ยน source audio เป็น target audio; ข้อดีคือไม่จำเป็นต้องใช้ข้อมูลที่ถูกจับคู่กันและไม่ต้องกำหนดระยะเวลาของเสียงให้เหมือนกันหมด
- ผลที่ออกมาหลังจากเทรนไปได้ 52 epochs ได้สังเกตว่าหลังจากที่ generate เพลงออกมานั้นเสียงร้องถูกกลืนเข้าไปกับเสียงของเครื่องดนตรีจึงหาวิธีการแก้ไขด้วย Spleeter ที่เป็น library สำหรับแยกเสียงเครื่องดนตรีหรือเสียงร้อง จึงนำมาใช้ preprocess ข้อมูลก่อนการเทรน
- ประเมินผลแยกเป็นแนวเพลง blues, rock และ country โดยให้คะแนน 1. ความเป็น Lo-Fi ของเพลง 2. เค้าโครงเดิมของเพลง; คะแนนอยู่ในช่วงประมาณ 3/5

### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)

> ผมอยู่ในยุคมี่ ai เริ่มเข้ามามีบทบาทในชีวิตมากขึ้น และจะเพิ่มขึ้นต่อไปเรื่อยๆในอนาคร ทำให้ผมมีความสนใจในด้าน ai เป็นอย่างมาก ได้เห็นสิ่งต่างๆเกี่ยวกับaiที่น่าทึ่งมาก อย่างเช่น chatgpt ที่เราสามารถถามข้อมูลแทบได้ทุกอย่าง หรือ midjourney ที่สามารถ generate รูปภาพที่เราต้องการจากข้อความที่เราพิมพ์ไปได้จึงทำให้ผมอยากรู้ว่าสิ่งเหล่านั้นมันถูกสร้างขึ้นมาอย่างไร สามารถเรียนรู้ให้เหมือนมนุษย์ได้อย่างไร ในระดับที่เจาะลึกลงไปผมเคยลงแข่งขัน kidbright coding & ai simulator online 2023 เป็นการแข่งขันสั่งการหุ่นยนต์ให้เดินตามเสียงโดยเราต้องทำการtrainเพื่อให้บอกทางได้แม่นยำมากที่สุด ตัวผมขณะนั้นสนใจaiแต่เดิมอยู่แล้วพอมีงานแข่งนี้ก็ทำให้ยิ่งสนใจเข้าไปอีก แล้วได้มาเจอกับโครงการai builder จากคุณครูในโรงเรียนจึงเห็นโอกาสในการพัฒนาตนเองเสริมความรู้ในด้านai อยากเข้าร่วมโครงการนี้ ซึ่งถ้าผมได้เข้าร่วมผมมั่นใจว่าผมสามารถนำความรู้ที่โครงการถ่ายทอดไปประยุกต์ใช้ด้านต่างๆในชีวิตประจำวัน
    