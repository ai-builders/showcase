---
date: "8-8-22"
title: "GANime-FullBody วาดรูปตัวละครอนิเมะ(สาวๆ)แบบเต็มตัว ด้วย Deep Learning"
builder: "หิรัญกุล พิมพ์ศิริ (ไกด์)"
builder_info: ""
thumbnail: "/images/2022/59/01.jpg"
links:
    github: "https://hrnph.github.io/GANime-FullBody/"
    facebook: "https://facebook.com/aibuildersx/posts/445888770912901"
    blog: "https://medium.com/@hrnph/%E0%B8%A7%E0%B8%B2%E0%B8%94%E0%B8%A3%E0%B8%B9%E0%B8%9B%E0%B8%95%E0%B8%B1%E0%B8%A7%E0%B8%A5%E0%B8%B0%E0%B8%84%E0%B8%A3%E0%B8%AD%E0%B8%99%E0%B8%B4%E0%B9%80%E0%B8%A1%E0%B8%B0%E0%B8%AA%E0%B8%B2%E0%B8%A7%E0%B9%86-%E0%B9%81%E0%B8%9A%E0%B8%9A%E0%B9%80%E0%B8%95%E0%B9%87%E0%B8%A1%E0%B8%95%E0%B8%B1%E0%B8%A7-%E0%B8%94%E0%B9%89%E0%B8%A7%E0%B8%A2-deep-learning-ganime-fullbody-9b3822e58934"
---

![image](/images/2022/59/01.jpg)

- โมเดล Generative Adversarial Network (GAN) สำหรับสร้างรูปวาดตัวละครสาวน้อยอนิเมะ; แรงบันดาลใจจากความชื่นชอบในอนิเมะและประสบการณ์ในการทำเกมที่จำเป็นต้องออกแบบตัวละครใหม่เรื่อยๆ จึงคิดว่าน่าจะสะดวกขึ้นหากมีโมเดลที่สร้างสาวน้อยอนิเมะออกมาให้เลือกปรับใช้กับทั้งเกม, ไลท์โนเวล, รูปประกอบ ฯลฯ,
- เลือกใช้ GAN มากกว่า Variational Autoencoder (VAE) เนื่องจากได้ภาพที่คมชัดกว่า; ด้วยข้อจำกัดทางเวลาและทรัพยากร ตั้งเป้าสร้างรูปขนาด 32², 64² หรือ 128² pixels,
- สร้างชุดข้อมูลขึ้นมาเองด้วยมาตรฐานว่ารูปต้อง 1) ไม่มีพื้นหลัง (ขาวล้วน) 2) ลายเส้นและลักษณะตรงความต้องการ (เต็มตัว, ลายเส้นญี่ปุ่น, ตัวละครหญิง) 3) ชุดข้อมูลที่มีขนาดใหญ่ เนื่องจาก GAN ต้องใช้ชุดข้อมูลจำนวนมาก (10k ++),
- เปรียบเทียบแหล่งข้อมูลที่จะรวบรวมมาเพื่อสร้างชุดข้อมูลหลายแห่ง เช่น Getchu ที่ปริมาณและคุณภาพดีที่สุดแต่การเชื่อมต่อไม่เสถียรพอ, Gelbooru ที่ปริมาณและคุณภาพดีเช่นกันแต่เต็มไปด้วยรูป 18+ จึงลงท้ายที่ Safebooru ซึ่งเป็น Gelbooru เวอร์ชั่นที่คัดรูป 18+ ออกแล้วโดยใช้แท้ก full_body solo, standing, 1girl, white_background เพื่อให้ได้รูปสาวน้อยอนิเมะเต็มตัวพื้นหลังสีขาว,
- ทำความสะอาดข้อมูลด้วยการคัดรูปต่อไปนี้ออก 1) ตัวละครจิบิ (หัวโตตัวเล็ก) 2) ภาพที่มีมากกว่า 1 ตัวละคร 3) พื้นหลังสีฉูดฉาด/ท่ายืนแปลกๆ; โดยตัวละครจิบิเป็นรูปประเภทที่ไม่ต้องการที่เยอะที่สุด,
- ทำโมเดลคัดแยกรูปที่ไม่ต้องการด้วย ResNet34 2 โมเดลคือ Chibi(~1k datasets) และ More Than 1(~0.3k datasets) ได้ผลอย่างดีเยี่ยม F1 0.96-0.98; เหลือชุดข้อมูลหลังทำความสะอาดแล้ว 12k รูป,
- ขั้นตอนการเทรนเริ่มจากใช้ DCGAN พบว่า generator (โมเดลสร้างภาพปลอม) แทบไม่ได้เรียนรู้เลยเพราะ discriminator (โมเดลจับว่าภาพจริงหรือปลอม) เรียนรู้เร็วจนเกินไป คาดว่าปัญหาเกิดจาก vanishing gradients ของ BCE Loss ที่ใช้กับ discriminator จึงเปลี่ยนมาใช้ Wasserstein Loss และเพิ่ม gradient penalty เพื่อไม่ให้ loss ลดลงใกล้ 0 เร็วจนเกินไป,
- จากนั้นปรับปรุงสถาปัตยกรรมโดยเปลี่ยนจาก DCGAN มาใช้ Progressive GAN ที่จะค่อยๆจับ Feature ที่ความละเอียดต่ำๆก่อน ในภาพ 4² เมื่อคุ้นชินแล้วก็จะเริ่มปรัปความละเอียดในสูงขึ้น เป็น 8² แล้วค่อยๆเพิ่มไปเรื่อยๆ จนถึง Scaling เป้าหมาย ที่ 128²,
- เพิ่มประสิทธิผลของ generator อีกขั้นโดยการปรับใช้เทคนิคจาก StyleGAN คือ 1) Mapping Network จัดเรียง Random Noise ให้มีรูปแบบ 2) Adaptive Instance Normalization (AdaIN) เพื่อทำ style transfer; StyleGAN ได้ผลดีพอๆกับ Progressive GAN โดยใช้เวลาที่สั้นกว่า; เทรนโมเดลด้วยสถาปัตยกรรมและชุดข้อมูลนี้ เรียกว่า Model A,
- เมื่อสถาปัตยกรรมเป็นที่พอใจแล้วกลับไปทำความสะอาดข้อมูลอีกรอบ เนื่องจากพบว่ารูปที่มี effect หรือชุดอลังการงานสร้างเกินไปจะทำให้โมเดลเรียนรู้ได้ยาก; ใช้ ResNet50 ในการคัดแยกรูปที่ต้องการและไม่ต้องการ โดยเทรนจากข้อมูลกำกับเองด้วยมือ 500 รูป, ได้ผลไม่ดีนัก (precision 0.4) ทำให้ข้อมูลถูกทำความสะอาดไปเหลือเพียงประมาณ 5 พันรูป,
- ลองเทรน Model B บนข้อมูล 5 พันรูปนั้นแล้วพบว่าความสวยงามเป็นที่น่าพึงพอใจแม้ปริมาณรูปจะลดลงเกินครึ่ง,
- ใช้ Fréchet inception distance (FID; ยิ่งน้อยยิ่งดี) ในการวัดผลเทียบรูปที่สร้างจาก Model A กับ Model B อย่างละ 1 หมื่นรูปกับรูปจริง พบว่า Model B ทำได้ดีกว่าเกือบเท่าตัว (data-centric มั้ยละคุณ!),
- แม้จะมีผลลัพท์ที่ออกมาน่ากลัวอยู่บ้าง แต่โดยรวมแล้วผลลัพท์ที่ออกมา ถือว่าน่าพึงพอใจ โมเดลสามารถจับดีเทลขาได้อย่างสวยงาม ชุดที่ถูกลักษณะ ร่างกายที่สมส่วน และยังพยายามเติมหน้าเข้าไปในทุกๆโมเดล; สิ่งที่จะพัฒนาต่อหลังจากนี้คือ 1) การทดลองปรัป Noise ของโมเดล และทดสอบ Latent W เพื่อหา Style แต่ละส่วน 2) การทำให้ภาพชัดขึ้นที่ 256² 3) การหา Datasets ที่ดีขึ้นเพื่อเพิ่มคุณภาพของโมเดล 4) การ Deploy ที่ผู้ใช้สามารถปรัป Style ของรูปได้,
- เปิดชุดข้อมูลลิขสิทธิ์การรวบรวมเป็น open source ที่: https://www.kaggle.com/datasets/hirunkulphimsiri/fullbody-anime-girls-datasets,
- เปิด Docker Image สำหรับ deploy API เป็น open source ที่: https://gallery.ecr.aws/z1f5v2y8/ganime-fullbody/model0

### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)

> "ผมไม่ค่อยเข้าร่วมกิจกรรมมากนัก เพราะพวกกิจกรรมที่มีมาบ่อยๆ ไม่ค่อยน่าสนใจ เช่นพวก open house หรือ แคมป์เสียเงินต่างๆ ผมชอบนั่งเรียนไปเรื่อยๆมากกว่า ดู Tutorials นั่นนี่แล้วก็ลองทำอะไรไปเรื่อยๆ ถ้าเวลาว่างๆ ผมก็จะไปตอบคำถามให้คำปรึกษาที่กลุ่มเฟสบุ๊ค/ดิสคอร์ด programming ครับ ได้ทบทวนความรู้ด้วย ได้ช่วยคนอื่นด้วย ผมว่าแบบนี้มันดีกว่าเยอะ ไม่ว่าใครจะว่ายังไง อันนี้ถือเป็นกิจกรรมที่ผมดีใจที่ได้ทำครับ  เพราะผมสนุกครับ สนุกกับการเรียนอะไรใหม่ๆ เรียนเรื่องที่ยังไม่เข้าใจ ได้แบ่งปันงานของตัวเองให้คนอื่นเอาไปพัฒนาต่อ หลักๆคือ เพราะว่ามันน่าสนุกผมเลยสมัครเข้ามา พอได้รู้อะไรมากขึ้นก็สอนคนอื่นได้มากขึ้นด้วย อีกอย่างคือผมอยากออกจากโลกแคบๆ อยากไปเจอคนใหม่ๆ ผมกังวลนความสามารถตัวเองมาตลอด ผมเลยอยากสร้างอะไรเจ๋งๆ ผมอยากพิสูจน์ตัวเอง ให้ตัวเองเห็นครับ"