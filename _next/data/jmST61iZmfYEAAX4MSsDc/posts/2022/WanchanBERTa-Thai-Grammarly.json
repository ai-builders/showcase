{"pageProps":{"postData":{"id":"WanchanBERTa-Thai-Grammarly","content":"\n![image](/images/2022/35/01.jpg)\n\n- โมเดลแก้การสะกดคำภาษาไทยด้วยเทคนิค tagging and masking โดยอาศัย WangchanBERTa เป็นโมเดลพื้นฐาน,\n- ปรับจูบนชุดข้อมูล VISTEC-TP-TH-2021 (https://github.com/mrpeerat/OSKut/blob/main/VISTEC-TP-TH-2021) ประกอบด้วยการสะกดคำผิด เช่น ตัวอักษรซ้ำ; มากกกกกก (มาก), รักๆๆๆๆ (รัก ๆ), ไม้ยมกโดยไม่เว้นช่องว่า; ขอบคุณๆ (ขอบคุณ ๆ), คำย่อโดยไม่มีจุด; มิย (มิ.ย.), วรรณยุกต์หาย; แป๊ป (แปป), พิมพ์ตก; อุหนุน (อุดหนุน), จงใจพิมพ์ผิด; นะ (น้า), ณ๊อง (น้อง), พิมพ์ไม่ครบ; อลัง (อลังการ), แบต (แบตเตอรี) เป็นต้น รวม 42,893 ประโยคที่มีการสะกดผิด,\n- ทำความสะอาดข้อมูลโดย เปลี่ยนรูปแบบประโยคจาก \"สวัสดี|<msp value=”ครับ”>ค้าบ</msp>|พี่|<ne>จอม</ne>\" เป็น \"สวัสดี^ครับ$พี่จอม\", เพิ่ม token สำหรับคำที่สะกดถูกเพื่อให้สามารถเติมคำได้ใน token เดียว, หาก token ที่สะกดผิดมีมากกว่าที่สะกดถูก ให้เติม _ ไปให้ครบเท่ากัน,\n- ทดลองใช้ hunspell, seq2seq และ tagging and masking,\n- tagging and masking ทำได้ดีที่สุด; โมเดลทำงานด้วยการชี้เป้า token ที่สะกดผิด (tagging; token classification) แล้วแทนที่ด้วย mask token จากนั้นให้โมเดลเดาว่า mask นั้นควรจะเป็นอะไร (masking),\n- ได้ accuracy 28.1% / F1 score 0.256 เทียบกับ hunspell และ seq2seq ที่แทบทายไม่ถูกเลย; ถ้าดูจาก BLEU รายประโยค จาก 1,000 ประโยคใน test set โมเดล tagging and masking แก้ถูก 386 ประโยค\n\n### แรงจูงในในการเข้าร่วมโครงการ (จากใบสมัครเข้าร่วมเมื่อ 10 สัปดาห์ที่แล้ว)\n\n> \"ผมมีความพร้อมและความปรารถนาในการเรียนรู้และประยุกต์ AI ผมมีพื้นฐานการเขียนโปรแกรม และผมยังมีความเข้าใจใน computer science ระดับหนึ่งจากโครงการคอมพิวเตอร์โอลิมปิกวิชาการ ในระดับค่ายสสวท. 1 นอกจากนี้ผมเคยเข้าโครงการ FIBO-School Consortium รุ่นที่ 5 ในสาขา deep learning ที่ผมได้เรียนรู้ intuition ของ neural network, CNN, fine-tuning และผมมีประสบการณ์ใน web development โดยผมมีโครงงานคอมพิวเตอร์ที่ใช้ Google Geolocation API ในการกำหนดพื้นที่แชร์ไฟล์ ส่วนตอนนี้ผมกำลังสร้างโปรเจคโดยใช้ MERN stack (MongoDB, Express, React, Node)  เมื่อก่อนนั้น AI เป็นสิ่งที่ค่อนข้างจะไกลตัว ไม่ว่าจะเป็นในด้านการใช้ประโยชน์หรือการหา resource เรียน แต่ในตอนนี้ AI กลายเป็นสิ่งที่มันเริ่มคืบคลานเข้ามาในชีวิตเรามากขึ้นและทุกคนก็สามารถเริ่มได้ แต่ด้วยประสบการณ์ของผมที่เคยเรียนสาย web development ผมบอกได้เลยว่า resource ของการเรียนเช่น MERN stack มันหาง่ายและ intuition ง่ายกว่าการเรียน AI ด้วยตัวเอง ผมเลยอยากจะใช้โอกาสนี้เพื่อศึกษา ทำความเข้าใจ และนำ AI มาปฏิบัติจริงในโครงการ AI Builder 2022 ที่มี mentor ผู้สามารถทำให้ผมกระจ่างในข้อสงสัยต่าง ๆ และเพื่อน ๆ ในโครงการที่จะคอยเรียนและผลักดันไปด้วยกัน ตอนนี้ผมพร้อมแล้วที่จะเข้าสู่ discipline แขนงนี้ไม่เหมือนเมื่อก่อนที่ผมยังขาด intuition บางส่วน เช่นการเขียนโปรแกรมเบื้องต้น หรือคณิตศาสตร์บางบท นอกจากนี้แล้วผมยังอยากจะมาสร้าง connection กับคนในโครงการนี้ไม่ว่าจะเป็น mentor หรือผู้สมัครโครงการ เพราะผมเชื่อว่าเป็นการเก็บจุดที่จะได้ใช้ในอนาคตแน่นอน เช่นผมอาจจะมีการทำงานร่วมกับคนในโครงการนี้ในอนาคต และผมรู้สึกว่า community ที่เกี่ยวกับคอมพิวเตอร์ในไทยนั้นมีความเกี่ยวพันกันมาก ผมก็พอจะสังเกตเห็นหลายคนที่มีส่วนร่วมในโอลิมปิกวิชาการมาทำ AI ฉะนั้นการทำความรู้จักคนมากก็ไม่ใช่สิ่งที่เสียหาย และยังอาจจะเปิดโอกาสให้ผมได้เรียนรู้จากคนอื่น ๆ อีกมากมาย\"","date":"15-7-22","title":"WanchanBERTa Thai Grammarly","builder":"อิทธิพัฒน์ ปานขำ (มาร์จิ้น)","builder_info":"","thumbnail":"/images/2022/35/01.jpg","links":{"github":"https://colab.research.google.com/github/bookpanda/WanchanBERTa-Thai-Grammarly/blob/main/demo.ipynb","facebook":"https://facebook.com/aibuildersx/posts/415235220644923","blog":"https://medium.com/@marginpankam/wanchanberta-thai-grammarly-5010671797c7"}}},"__N_SSG":true}